model:
  base_model: "meta-llama/Llama-3.2-1B"
  quant:
    load_in_4bit: true
    double_quant: true
    quant_type: "nf4"
    compute_dtype: "bfloat16"
lora:
  r: 256
  alpha: 512
  dropout: 0.05
trainer:
  epochs: 50
  output_dir: "meta-llama/Llama-3.2-1B-SFT"
data:
  pdf_path: "tm1_dg_dvlpr-10pages.pdf"
  dataset_file: "tm1data.json"
  instruction_file: "data/instruction.json"
